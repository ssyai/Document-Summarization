{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d17e3c-3060-4c07-9ea0-fd3ea60044db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1136730f-91a0-49eb-8547-836718e3d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy dataset\n",
    "legal_documents = [\n",
    "    \"In the event of a default by either party, this agreement may be terminated by written notice to the defaulting party.\",\n",
    "    \"The lessee shall maintain the property in good condition and make any necessary repairs.\",\n",
    "    \"Confidential information shall not be disclosed to any third party without prior written consent.\",\n",
    "    \"The party shall indemnify and hold harmless the other party from any claims arising out of the performance of this agreement.\",\n",
    "    \"The buyer shall pay the seller the purchase price in accordance with the terms set forth herein.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34469e61-23e2-4d45-bbc9-ea757a242fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Tokenization & Embedding\n",
    "# Load Sentence Transformer Model for Embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for each document\n",
    "document_embeddings = embedding_model.encode(legal_documents, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed2c224-bfe9-4bf7-acaa-600161de5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAISS Vector database for retrieval\n",
    "# Convert embeddings to numpy array\n",
    "document_embeddings_np = document_embeddings.detach().cpu().numpy()\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = document_embeddings_np.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add document embeddings to the FAISS index\n",
    "index.add(document_embeddings_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c35a2ea-24a8-4f89-84e5-69c933616292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents: ['In the event of a default by either party, this agreement may be terminated by written notice to the defaulting party.', 'The party shall indemnify and hold harmless the other party from any claims arising out of the performance of this agreement.']\n"
     ]
    }
   ],
   "source": [
    "#RAG\n",
    "# Function to retrieve similar documents\n",
    "def retrieve_similar_documents(query, top_k=2):\n",
    "    query_embedding = embedding_model.encode([query], convert_to_tensor=True).detach().cpu().numpy()\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    return [legal_documents[idx] for idx in indices[0]]\n",
    "\n",
    "# Test Retrieval Function\n",
    "test_query = \"What are the terms for termination?\"\n",
    "similar_docs = retrieve_similar_documents(test_query)\n",
    "print(\"Retrieved Documents:\", similar_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33b5f9b-e94a-4d59-8032-d44de6efa1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: This agreement may be terminated by written notice to the defaulting party. In the event of a default by either party, this agreement could be terminated.\n",
      "Summary: summarize: The party shall indemnify and hold harmless the other party from any claims arising out of the performance of this agreement. The parties agree that they will not sue each other for damages.\n"
     ]
    }
   ],
   "source": [
    "#Fine-Tuning (PEFT) with Prompt Engineering\n",
    "# Load Pre-trained BERT Summarization Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Function to Generate Summaries\n",
    "def generate_summary(text, max_length=50):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Test Summarization\n",
    "for doc in similar_docs:\n",
    "    summary = generate_summary(doc)\n",
    "    print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ea581e-4c8c-4f0a-bc17-dc4a98b8bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Time (ms): 164.3538475036621\n"
     ]
    }
   ],
   "source": [
    "#Measure performance: document retrieval speed, summarization accuracy\n",
    "import time\n",
    "\n",
    "# Measure Retrieval Speed\n",
    "start_time = time.time()\n",
    "retrieve_similar_documents(test_query)\n",
    "end_time = time.time()\n",
    "print(\"Retrieval Time (ms):\", (end_time - start_time) * 1000)\n",
    "\n",
    "# Accuracy and Summary Length could be computed by comparing against a ground-truth set if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e09bfb-4a2e-406c-bfef-3012dac5cfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
